import unittest
import time
import pytest
from pydub import AudioSegment
from google.oauth2 import service_account
from google.cloud import storage, speech_v1
import json
import os
import re
import wave
import whisper
from itertools import groupby
import threading


class STT_Test(unittest.TestCase):
    # 테스트 대상 파일
    audio_path = "./VisualRadio/MyTest/sec_1.wav"

    # @pytest.fixture(scope='function')
    # def operation(self):
    #     # 필요 클라이언트 생성과 세팅
    #     project_id = 'RadioProject'
    #     bucket_name = 'radio_bucket'
    #     credentials = service_account.Credentials.from_service_account_file('./VisualRadio/credentials.json')
    #     client = speech_v1.SpeechClient(credentials=credentials)
    #     storage_client = storage.Client(project=project_id, credentials=credentials)
    #     bucket = storage_client.bucket(bucket_name)

    #     blob = bucket.blob(os.path.basename(self.audio_path))
    #     blob.upload_from_filename(self.audio_path)
    #     storage_file_path = f'gs://{bucket_name}/{blob.name}'
    #     audio = speech_v1.RecognitionAudio(uri=storage_file_path)
    #     config = speech_v1.RecognitionConfig(
    #         language_code='ko-KR',
    #     )
    #     operation = client.long_running_recognize(config=config, audio=audio)
    #     yield operation


    # @pytest.fixture(scope='function')
    # def google_result_1(operation):
    #     response = operation.result(timeout=999999)
    #     results = response.results
    #     yield results

    # @pytest.fixture(scope='function')
    # def google_result_2(self, google_result_1):
        
    #     def flac_duration(audio_path):
    #         audio = AudioSegment.from_file(audio_path, format="flac")
    #         duration_micros = int(audio.duration_seconds * 1000000)
    #         minutes, seconds = divmod(duration_micros / 1000000, 60)
    #         microseconds = duration_micros % 1000
    #         duration =  "{:d}:{:02d}.{:03d}".format(int(minutes), int(seconds), microseconds)
    #         return duration

    #     # stt결과 저장 경로
    #     import os
    #     save_path = "./VisualRadio/MyTest/results/stt_google.json"
    #     if os.path.exists(save_path):
    #         os.remove(save_path)

    #     # start_time을 0분 0초로 초기화
    #     import datetime
    #     start_time_delta = datetime.timedelta(hours=0, minutes=0, seconds=0, microseconds=0)
    #     m, s = divmod(start_time_delta.seconds, 60)
    #     start_time_formatted = "{:d}:{:02d}.{:03d}".format(m, s, start_time_delta.microseconds)

    #     # 스크립트에 time, text 정보 작성하기
    #     import json
    #     scripts = []
    #     for result in google_result_1:
    #         alternative = result.alternatives[0]  
    #         new_data = {'time': start_time_formatted, 'txt': alternative.transcript}
    #         scripts.append(json.dumps(new_data, ensure_ascii=False))
    #         # start time 갱신
    #         start_time_delta = result.result_end_time
    #         m, s = divmod(start_time_delta.seconds, 60)
    #         start_time_formatted = "{:d}:{:02d}.{:03d}".format(m, s, start_time_delta.microseconds)
    #     end_time = str(flac_duration(self.audio_path))
    #     data = {'end_time':end_time, 'scripts':[json.loads(s) for s in scripts]}
    #     with open(save_path, 'w', encoding='utf-8') as f:
    #         json.dump(data, f,  ensure_ascii=False)
    #     yield save_path
    

    # @pytest.fixture
    def test_get_whisper_result(self):
        def flac_duration(audio_path):
            audio = AudioSegment.from_file(audio_path, format="flac")
            duration_micros = int(audio.duration_seconds * 1000000)
            minutes, seconds = divmod(duration_micros / 1000000, 60)
            microseconds = duration_micros % 1000
            duration =  "{:d}:{:02d}.{:03d}".format(int(minutes), int(seconds), microseconds)
            return duration
        def format_time(time_in_seconds):
            time_in_seconds = float(time_in_seconds)
            minutes, seconds = divmod(int(time_in_seconds), 60)
            milliseconds = int((time_in_seconds - int(time_in_seconds)) * 1000)
            return "{:d}:{:02d}.{:03d}".format(minutes, seconds, milliseconds)
        def show_progress(message):
            seconds = 0
            while is_running:
                print(f"[로딩] {message}... {seconds}초 지났어...♥")
                time.sleep(1)
                seconds += 1
            print("작업 중단")

        # device = "cuda" if torch.cuda.is_available() else "cpu"
        device = "cpu"
        language = "ko"
        model = whisper.load_model("base").to(device)

        print(f"audio : {self.audio_path}")
        
        # stt작업 하기 
        is_running = True
        thread = threading.Thread(target=show_progress, args=("whisper stt", ))
        thread.start()
        results = model.transcribe(
            self.audio_path, language=language, temperature=0.0, word_timestamps=True
        )
        is_running = False
        thread.join()

        # 스크립트 만들기
        scripts = []
        lines = []
        times = []
        for result in results['segments']:
            text = result['text']
            endings = ['에요', '해요', '예요', '지요', '네요', '[?]{1}', '[가-힣]{1,2}시다', '[가-힣]{1,2}니다', '어요', '구요', '군요', '어요', '아요', '은요', '이요', '든요', '워요', '드리고요', '되죠', '하죠']
            end_position = len(text)
            end_word = None
            for ending in endings:
                pattern = re.compile(ending)
                match = pattern.search(text)
                if match:
                    now_position = match.start()
                    if now_position < end_position:
                        end_position = now_position
                        end_word = ending
                else:
                    pass
            # 시간 처리
            lines.append(text)
            times.append(result['start'])
            if end_word != None:
                scripts.append({'time':format_time(times[0]), 'txt':''.join(lines)})
                lines = []
                times = []

        # 결과물의 끝까지 종결 어미가 안나오는 경우
        unique_lines = [k for k, _ in groupby(lines)]
        if len(times) != 0:
            scripts.append({'time':format_time(times[0]), 'txt':''.join(unique_lines)})

        # 처리
        with wave.open(self.audio_path, 'rb') as wav_file:
            sample_rate = wav_file.getframerate()
            num_frames = wav_file.getnframes()
            duration = num_frames / sample_rate
        data = {'end_time':format_time(duration), 'scripts':[s for s in scripts]}
        with open('./VisualRadio/MyTest/results/whi.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False)

    # def test_match_google_and_whisper_sync(google_result_2, get_whisper_result):
    #     print(google_result_2)
    #     print(get_whisper_result)


if __name__ == '__main__':
    unittest.main()
